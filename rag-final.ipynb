{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24f8279-278a-4533-aa21-60e770655e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32aabc-07cc-47d2-8713-334e0af6222f",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e67e77-460f-4e0c-a363-89a175ee57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade langchain langchain-community langchain-chroma\n",
    "!pip install --quiet langchain-openai\n",
    "!pip install --quiet pypdf\n",
    "!pip install --quiet sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd68b3-55d3-4fdb-9b91-65fcd91c5281",
   "metadata": {},
   "source": [
    "# Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08816c10-5cec-476d-b673-83fa40c1b8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser  # For the chains\n",
    "from langchain_core.runnables import RunnablePassthrough   # For the chains\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader #For PDF Loader\n",
    "from langchain_mistralai import ChatMistralAI #For MISTRAL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5651df-5764-4a12-8c37-611d1ec2f6f0",
   "metadata": {},
   "source": [
    "# Selected Model: Mistral 7B\n",
    "\n",
    "We have selected the **Mistral model** with **7 billion parameters**, and we are accessing it remotely using a Mistral API Key.\n",
    "\n",
    "## Reasons for Selection\n",
    "1. **Open-Source**: Being open-source allows for customization and adaptability.\n",
    "2. **Relatively Small Size**: With 7B parameters, it offers a good balance between performance and computational cost, making it feasible to use locally with proper quantization.\n",
    "3. **Proven Performance**: The model has shown excellent results across various tasks, proving effective in multiple contexts.\n",
    "\n",
    "*Mistral context window has 32.8k size which is proximatly 20,000–25,000 words*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74691e4f-7c9c-4697-9c92-892794e8e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatMistralAI(model=\"open-mistral-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcadfb8-60d9-465b-b589-1a29c90cb6b8",
   "metadata": {},
   "source": [
    "# Indexing: Load (PDF)\n",
    "We use PyPDFLoader for loading local pdf, but we mihgt change that for web Documents loadin, later with  **WebBaseLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ce9dc07-b667-49ad-811c-c361d8af32ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1882"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "# Replace this with the path to your local PDF file\n",
    "pdf_file_path = \"ArtificialIntelligenceAct-1-50.pdf\"\n",
    "# Load the local PDF file\n",
    "loader = PyPDFLoader(pdf_file_path)\n",
    "# Load and process the document\n",
    "docs = loader.load()\n",
    "\n",
    "len(docs[0].page_content) #here docs is already an LangChain Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00bd0a-1b98-46c0-8094-45eaf2153d4f",
   "metadata": {},
   "source": [
    "# Indexing: Split\n",
    "\n",
    "we use Chroma as our Vector Store\n",
    "we use all-MiniLM-L6-v2 from Microsoftmodel to create the Embeddings. (OpenAI are pay to use)\n",
    "\n",
    "The chunk size is an balanced Value considering on the Mistral and embedding model context window size which seems to work good on practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf307ce4-23db-484d-b376-5ddd8bcc5699",
   "metadata": {},
   "source": [
    "# Indexing: Split\n",
    "\n",
    "we use Chroma as our Vector Store\n",
    "we use all-MiniLM-L6-v2 from Microsoftmodel to create the Embeddings. (OpenAI are pay to use)\n",
    "\n",
    "The chunk size is an balanced Value considering on the Mistral and embedding model context window size which seems to work good on practice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b786a0bd-ed5e-488d-8097-b73cae4b3a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chunks: 115\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"number of chunks: {len(splits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ac69c-56d4-4a81-b4b3-3a7349cb37a6",
   "metadata": {},
   "source": [
    "# Indexing: Store Embeddings\n",
    "- **Chroma** is an open-source **vector database** that’s designed for scalable, high-performance **similarity search**.\n",
    "- The model **all-MiniLM-L6-v2** is part of the MiniLM (Mini Language Models) family developed by **Microsoft**. Especially suited for **semantic similarity** tasks, **sentence embedding**, and **question-answer retrieval**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61f38d84-1a6d-4f19-896e-536d34f71306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perei\\AppData\\Local\\Temp\\ipykernel_3556\\1528764191.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  vectorstore = Chroma.from_documents(documents=splits, embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n",
      "c:\\Users\\perei\\miniconda3\\envs\\chatbot\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits, embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d22a39-8e4d-483c-864b-620c022695a3",
   "metadata": {},
   "source": [
    "#  Retrieval and Generation: Retrieve\n",
    "## Retreiver:\n",
    "We're using the most common type of Retriever wich is the VectorStoreRetriever.\n",
    "## Prompt:\n",
    "The prompt that is being pulled from *https://smith.langchain.com/hub/rlm/rag-prompt*: \n",
    "\n",
    "\"\n",
    "`HUMAN`\n",
    "\n",
    "`You are an assistant for question-answering tasks. Use the following retrieved context to answer the question. If you don't know the answer, state that clearly. Limit your response to three sentences, keeping the answer concise.`\n",
    "\n",
    "\n",
    "`Question: {question}`\n",
    "\n",
    "`Context: {context}`\n",
    "\n",
    "`Answer:`\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70eb0494-ea60-4002-9bf9-4ace03a83f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\perei\\miniconda3\\envs\\chatbot\\Lib\\site-packages\\langsmith\\client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever(\n",
    "                search_type=\"similarity_score_threshold\",\n",
    "                search_kwargs={'score_threshold': 0.0}\n",
    "            )\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a143ba-dcf9-42f5-8cd4-4a430d0e2f09",
   "metadata": {},
   "source": [
    "# Retrieval and Generation: Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3979ec7-a9e4-4e78-84cb-275735fa3b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'page': 47, 'source': 'ArtificialIntelligenceAct-1-50.pdf'}, page_content='(52) As regards stand-alone AI systems, namely high-risk AI systems other than those that are \\nsafety components of products, or that are themselves products, it is appropriate to classify \\nthem as high-risk if, in light of their intended purpose, they pose a high risk of harm to the \\nhealth and safety or the fundamental rights of persons, taking into account both the severity \\nof the possible harm and its probability of occurrence and they are used in a number of \\nspecifically pre-defined areas specified in this Regulation. The identification of those \\nsystems is based on the same methodology and criteria envisaged also for any future \\namendments of the list of high-risk AI systems that the Commission should be \\nempowered to adopt, via delegated acts, to take into account the rapid pace of \\ntechnological development, as well as the potential changes in the use of AI systems.'), Document(metadata={'page': 49, 'source': 'ArtificialIntelligenceAct-1-50.pdf'}, page_content='and transparency, a provider who considers that an AI system is not high-risk on the \\nbasis of the conditions referred to above should draw up documentation of the \\nassessment before that system is placed on the market or put into service and should \\nprovide that documentation to national competent authorities upon request. Such a \\nprovider should be obliged to register the AI system in the EU database established \\nunder this Regulation. With a view to providing further guidance for the practical \\nimplementation of the conditions under which the AI systems listed in an annex to this \\nRegulation are, on an exceptional basis, non-high-risk, the Commission should, after \\nconsulting the Board, provide guidelines specifying that practical implementation, \\ncompleted by a comprehensive list of practical examples of use cases of AI systems that \\nare high-risk and use cases that are not.'), Document(metadata={'page': 46, 'source': 'ArtificialIntelligenceAct-1-50.pdf'}, page_content='aviation.\\n(51) The classification of an AI system as high-risk pursuant to this Regulation should not \\nnecessarily mean that the product whose safety component is the AI system, or the AI \\nsystem itself as a product, is considered to be high-risk under the criteria established in the \\nrelevant Union harmonisation legislation that applies to the product. This is, in particular, \\nthe case for Regulations (EU) 2017/745 and (EU) 2017/746, where a third-party \\nconformity assessment is provided for medium-risk and high-risk products.'), Document(metadata={'page': 45, 'source': 'ArtificialIntelligenceAct-1-50.pdf'}, page_content='appropriate to amend those acts to ensure that the Commission takes into account, on the \\nbasis of the technical and regulatory specificities of each sector, and without interfering \\nwith existing governance, conformity assessment and enforcement mechanisms and \\nauthorities established therein, the mandatory requirements for high-risk AI systems laid \\ndown in this Regulation when adopting any relevant delegated or implementing acts on the \\nbasis of those acts.')]\n",
      "Number of relevant documents: 4\n",
      "\n",
      "Document 1:\n",
      "(52) As regards stand-alone AI systems, namely high-risk AI systems other than those that are \n",
      "safety components of products, or that are themselves products, it is appropriate to classify \n",
      "them as high-risk if, in light of their intended purpose, they pose a high risk of harm to the \n",
      "health and safety or the fundamental rights of persons, taking into account both the severity \n",
      "of the possible harm and its probability of occurrence and they are used in a number of \n",
      "specifically pre-defined areas specified in this Regulation. The identification of those \n",
      "systems is based on the same methodology and criteria envisaged also for any future \n",
      "amendments of the list of high-risk AI systems that the Commission should be \n",
      "empowered to adopt, via delegated acts, to take into account the rapid pace of \n",
      "technological development, as well as the potential changes in the use of AI systems.\n",
      "--------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "and transparency, a provider who considers that an AI system is not high-risk on the \n",
      "basis of the conditions referred to above should draw up documentation of the \n",
      "assessment before that system is placed on the market or put into service and should \n",
      "provide that documentation to national competent authorities upon request. Such a \n",
      "provider should be obliged to register the AI system in the EU database established \n",
      "under this Regulation. With a view to providing further guidance for the practical \n",
      "implementation of the conditions under which the AI systems listed in an annex to this \n",
      "Regulation are, on an exceptional basis, non-high-risk, the Commission should, after \n",
      "consulting the Board, provide guidelines specifying that practical implementation, \n",
      "completed by a comprehensive list of practical examples of use cases of AI systems that \n",
      "are high-risk and use cases that are not.\n",
      "--------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "aviation.\n",
      "(51) The classification of an AI system as high-risk pursuant to this Regulation should not \n",
      "necessarily mean that the product whose safety component is the AI system, or the AI \n",
      "system itself as a product, is considered to be high-risk under the criteria established in the \n",
      "relevant Union harmonisation legislation that applies to the product. This is, in particular, \n",
      "the case for Regulations (EU) 2017/745 and (EU) 2017/746, where a third-party \n",
      "conformity assessment is provided for medium-risk and high-risk products.\n",
      "--------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "appropriate to amend those acts to ensure that the Commission takes into account, on the \n",
      "basis of the technical and regulatory specificities of each sector, and without interfering \n",
      "with existing governance, conformity assessment and enforcement mechanisms and \n",
      "authorities established therein, the mandatory requirements for high-risk AI systems laid \n",
      "down in this Regulation when adopting any relevant delegated or implementing acts on the \n",
      "basis of those acts.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The AI Act aims to regulate high-risk AI systems by classifying them as such if they pose a high risk of harm to health, safety, or fundamental rights, considering both the severity and probability of harm. Providers of non-high-risk AI systems should document their assessment and register the system in an EU database. For clarity, the Commission may provide guidelines and examples. The classification of an AI system as high-risk does not necessarily mean the same for the product it's a part of, depending on the relevant Union harmonization legislation.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()  #because some meta_data might come along with the text. Only extract the text\n",
    ")\n",
    "\n",
    "query = \"How does the AI Act aim to regulate high-risk AI systems?\"\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "print(\"Number of relevant documents:\", len(relevant_docs), end=\"\\n\\n\") # Default is 4\n",
    "\n",
    "for i, doc in enumerate(relevant_docs, start=1):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "rag_chain.invoke(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bee5f7",
   "metadata": {},
   "source": [
    "## Description of the Chatbot Interface\n",
    "\n",
    "The chatbot interface was developed using the **Streamlit** library, a popular tool for rapidly and interactively creating web applications. Below are the main components and functionalities of the interface:\n",
    "\n",
    "1. **Loading Environment Variables**:\n",
    "   - The code uses the `dotenv` library to load environment variables, such as the API key for the language model (Mistral), allowing the application to securely access sensitive configurations.\n",
    "\n",
    "2. **Model Initialization**:\n",
    "   - The `ChatMistralAI` language model is initialized with the API key. This model is responsible for generating responses based on user questions.\n",
    "\n",
    "3. **Loading and Processing Documents**:\n",
    "   - Users can upload documents in PDF format. These files are processed into smaller parts (chunks) to facilitate the retrieval of relevant information during interactions.\n",
    "\n",
    "4. **Message History**:\n",
    "   - The application maintains a history of messages to provide context for responses. The history is limited to a maximum number of responses (set to 5), ensuring that previous interactions are considered without overloading the model's memory.\n",
    "\n",
    "5. **User Input**:\n",
    "   - The interface presents an input field where users can type their questions. Once a question is submitted, the interface records the message and calls the function responsible for generating a response.\n",
    "\n",
    "6. **Message Display**:\n",
    "   - The messages exchanged between the user and the chatbot are displayed in the interface in a chat format, using the `st.chat_message` function to enhance readability.\n",
    "\n",
    "7. **Dynamic Interaction**:\n",
    "   - The interface responds dynamically to file uploads and message submissions. If a file is successfully uploaded, the chatbot can generate responses based on the content of that file in response to user questions.\n",
    "\n",
    "8. **Error Handling**:\n",
    "   - If no file has been uploaded and the user attempts to submit a question, a message will be displayed prompting the user to upload a file before continuing.\n",
    "\n",
    "This approach provides an interactive and user-friendly experience, allowing users to query data contained in the documents they upload and receive informative responses from the chatbot seamlessly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
