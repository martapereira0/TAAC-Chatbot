{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install sentence-transformers\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        text = ''\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + '\\n'\n",
    "    return text\n",
    "\n",
    "def save_chunks_to_txt(chunks, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            f.write(f\"Chunk {i+1}:\\n\")\n",
    "            f.write(chunk)\n",
    "            f.write(\"\\n\" + \"-\"*40 + \"\\n\")  \n",
    "\n",
    "file_path = 'ArtificialIntelligenceAct-1-50.pdf'  \n",
    "pdf_text = read_pdf(file_path)\n",
    "\n",
    "# testar valores e splitters e no final ver quais os melhores\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_text(pdf_text)\n",
    "output_file = 'chunks.txt'\n",
    "\n",
    "save_chunks_to_txt(chunks, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "embeddings = model.encode(chunks)\n",
    "print(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Armazenar embeddings numa DB vetorial p ex qdrant, postgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "# UI : http://localhost:6333/dashboard\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"test_collection\",\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation_id=0 status=<UpdateStatus.COMPLETED: 'completed'>\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "points = [\n",
    "    PointStruct(id=i, vector=embedding.tolist(), payload={\"text\": chunk})\n",
    "    for i, (embedding, chunk) in enumerate(zip(embeddings, chunks))\n",
    "]\n",
    "\n",
    "operation_info = client.upsert(\n",
    "    collection_name=\"test_collection\",\n",
    "    points=points,\n",
    "    wait=True\n",
    ")\n",
    "print(operation_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "ex = \"What is Artificial Intelligence Act?\"\n",
    "query = model.encode(ex)\n",
    "print(len(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Resultado ID: 10, Texto: and level of technological development, AI may generate risks and cause harm to public\n",
      "interests and fundamental rights that are protected by Union law. Such harm might be\n",
      "material or immaterial, including physical, psychological, societal or economic harm.\n",
      "(6) Given the major impact that AI can have on society and the need to build trust, it is vital\n",
      "for AI and its regulatory framework to be developed in accordance with Union values as\n",
      "enshrined in Article 2 of the Treaty on European Union (TEU), the fundamental rights\n",
      "and freedoms enshrined in the Treaties and, pursuant to Article 6 TEU, the Charter. As\n",
      "a pre-requisite, AI should be a human-centric technology. It should serve as a tool for\n",
      "people, with the ultimate aim of increasing human well-being.\n",
      "(7) In order to ensure a consistent and high level of protection of public interests as regards\n",
      "health, safety and fundamental rights, common rules for high-risk AI systems should be\n"
     ]
    }
   ],
   "source": [
    "\"\"\"search_result = client.query_points(\n",
    "    collection_name=\"test_collection\",\n",
    "    query=query,\n",
    "    with_payload=False,\n",
    "    limit=3\n",
    ").points\n",
    "\n",
    "print(search_result)\"\"\"\n",
    "pergunta = \"How does the Artificial Intelligence Act address the potential risks posed by AI systems to fundamental rights and public safety in the EU?\"\n",
    "query_vector = model.encode([pergunta])[0]  \n",
    "\n",
    "\n",
    "search_result = client.search(\n",
    "    collection_name=\"test_collection\",  \n",
    "    query_vector=query_vector.tolist(),  \n",
    "    limit=1 \n",
    ")\n",
    "\n",
    "\n",
    "print(\"Results:\")\n",
    "for hit in search_result:\n",
    "    print(f\"Resultado ID: {hit.id}, Texto: {hit.payload['text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
