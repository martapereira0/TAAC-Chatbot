{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "# QhdyPvS28vnpVY94g5YKmm58PgEhUCYb\n",
    "os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_file_path = \"ArtificialIntelligenceAct.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_file_path)\n",
    "\n",
    "# Load and process the document\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Chunks, generate the embeddings and store them\n",
    "The model we used for generating the embeddings was the ``all-MiniLM-L6-v2`` of Hugging Face.\n",
    "\n",
    "Then we stored those embeddings in a vectorial data base (Chroma).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perei\\AppData\\Local\\Temp\\ipykernel_16604\\4226516271.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  vectorstore = Chroma.from_documents(documents=splits, embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n",
      "c:\\Users\\perei\\miniconda3\\envs\\chatbot\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\perei\\miniconda3\\envs\\chatbot\\Lib\\site-packages\\langsmith\\client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'page': 329, 'source': 'ArtificialIntelligenceAct.pdf'}, page_content='The Board may establish other standing or temporary sub-groups as appropriate for the \\npurpose of examining specific issues. Where appropriate, representatives of the advisory \\nforum referred to in Article 67 may be invited to such sub-groups or to specific meetings \\nof those subgroups as observers.\\n7. The Board shall be organised and operated so as to safeguard the objectivity and \\nimpartiality of its activities.\\n8. The Board shall be chaired by one of the representatives of the Member States. The AI \\nOffice shall provide the secretariat for the Board, convene the meetings upon request of \\nthe Chair, and prepare the agenda in accordance with the tasks of the Board pursuant to \\nthis Regulation and its rules of procedure.\\nArticle 66\\nTasks of the Board\\nThe Board shall advise and assist the Commission and the Member States in order to facilitate \\nthe consistent and effective application of this Regulation. To that end, the Board may in \\nparticular:'), Document(metadata={'page': 328, 'source': 'ArtificialIntelligenceAct.pdf'}, page_content='(b) are designated as a single contact point vis-à-vis the Board and, where appropriate, \\ntaking into account Member States’ needs, as a single contact point for \\nstakeholders;\\n(c) are empowered to facilitate consistency and coordination between national \\ncompetent authorities in their Member State as regards the implementation of this \\nRegulation, including through the collection of relevant data and information for \\nthe purpose of fulfilling their tasks on the Board.\\n5. The designated representatives of the Member States shall adopt the Board’s rules of \\nprocedure by a two-thirds majority. The rules of procedure shall, in particular, lay down \\nprocedures for the selection process, the duration of the mandate of, and specifications \\nof the tasks of, the Chair, detailed arrangements for voting, and the organisation of the \\nBoard’s activities and those of its sub-groups.\\n6. The Board shall establish two standing sub-groups to provide a platform for cooperation'), Document(metadata={'page': 339, 'source': 'ArtificialIntelligenceAct.pdf'}, page_content='Section 2\\nNational competent authorities\\nArticle 70\\nDesignation of national competent authorities and single points of contact\\n▌\\n1. Each Member State shall establish or designate as national competent authorities at least \\none notifying authority and at least one market surveillance authority for the purposes of \\nthis Regulation. Those national competent authorities shall exercise their powers \\nindependently, impartially and without bias so as to safeguard the objectivity of their \\nactivities and tasks, and to ensure the application and implementation of this Regulation. \\nThe members of those authorities shall refrain from any action incompatible with their \\nduties. Provided that those principles are observed, such activities and tasks may be \\nperformed by one or more designated authorities, in accordance with the organisational \\nneeds of the Member State.'), Document(metadata={'page': 333, 'source': 'ArtificialIntelligenceAct.pdf'}, page_content='(o) receive opinions by the Member States on qualified alerts regarding general-purpose AI \\nmodels, and on national experiences and practices on the monitoring and enforcement \\nof AI systems, in particular systems integrating the general-purpose AI models.\\nArticle 67\\nAdvisory forum\\n1. An advisory forum shall be established to provide technical expertise and advise the \\nBoard and the Commission, and to contribute to their tasks under this Regulation.\\n2. The membership of the advisory forum shall represent a balanced selection of \\nstakeholders, including industry, start-ups, SMEs, civil society and academia. The \\nmembership of the advisory forum shall be balanced with regard to commercial and \\nnon-commercial interests and, within the category of commercial interests, with regard \\nto SMEs and other undertakings.\\n3. The Commission shall appoint the members of the advisory forum, in accordance with \\nthe criteria set out in paragraph 2, from amongst stakeholders with recognised expertise')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perei\\AppData\\Local\\Temp\\ipykernel_16604\\1512139187.py:15: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(retriever.get_relevant_documents(\"Hi\"))\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever(\n",
    "                search_type=\"similarity_score_threshold\",\n",
    "                search_kwargs={'score_threshold': 0.8}\n",
    "            )\n",
    "            \n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\"\"\"Prompt template:\n",
    "    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "    Question: {question} \n",
    "\n",
    "    Context: {context} \n",
    "\n",
    "    Answer:\n",
    "\"\"\"\n",
    "\n",
    "print(retriever.get_relevant_documents(\"Hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\perei\\miniconda3\\envs\\chatbot\\Lib\\site-packages\\langsmith\\client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['documents', 'student_answer'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'langchain-ai', 'lc_hub_repo': 'rag-context-recall', 'lc_hub_commit_hash': '8b6ffd487ad2a66c0fc129ee1e3d4854336c7fd736405af0b9b1a0ffb63d51e8'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a teacher grading a quiz. \\n\\nYou will be given a STUDENT ANSWER and a set of FACTS. \\n\\nHere is the grade criteria to follow:\\n(1) Look at each sentence in the STUDENT ANSWER.\\n(2) Determine whether the sentence can be attributed to the FACTS.\\n(3) Assign a score of 1 if the sentence can be attributed to the FACTS \\n(4) Assign a score of 0 if the sentence can NOT be attributed to the FACTS \\n\\nScore:\\nReturn the fraction: The number of sentences that can be attributed to the FACTS and got a score of 1 divided by the total number of sentences.\\n\\nExplain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \\n\\nAvoid simply stating the correct answer at the outset.', template_format='mustache'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['documents', 'student_answer'], input_types={}, partial_variables={}, template='STUDENT ANSWER: {{student_answer}}\\nFACTS: {{documents}}', template_format='mustache'), additional_kwargs={})] schema_={'type': 'object', 'title': 'Grade', 'required': ['Score', 'Explanation'], 'properties': {'Score': {'type': 'number', 'description': 'Provide the score:'}, 'Explanation': {'type': 'string', 'description': 'Explain your reasoning for the score:'}}, 'description': 'Grade the quiz based upon the above criteria with a score and your explanation for the score.'} structured_output_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "print(hub.pull(\"langchain-ai/rag-context-recall\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo : MistralAI através da Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The AI Act aims to regulate high-risk AI systems by requiring operators to comply with its requirements by specific deadlines. For high-risk AI systems used by public authorities, this is within six years of the Regulation's entry into force. For systems already in use before this date, compliance is required if they undergo significant changes. Providers of high-risk AI systems are encouraged to comply during the transitional period. (178, 2, 3)\\n\\nHigh-risk AI systems are defined as those that pose a high risk of harm to health, safety, or fundamental rights, and are used in specified areas. These systems are subject to harmonized rules, prohibitions of certain AI practices, and specific requirements. (52)\\n\\nThe AI Act's purpose is to improve the internal market, promote human-centric and trustworthy AI, and ensure a high level of protection against harmful AI effects. It lays down harmonized rules, prohibitions, and requirements for high-risk AI systems. (1)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "llm = ChatMistralAI(model=\"open-mistral-7b\", api_key=os.environ[\"MISTRAL_API_KEY\"])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Pipeline de RAG\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "#rag_chain.invoke(\"What are the main values enshrined in the AI Act, according to Union law?\")\n",
    "#rag_chain.invoke(\"What are the primary objectives of the Artificial Intelligence Act?\")\n",
    "rag_chain.invoke(\"How does the AI Act aim to regulate high-risk AI systems?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
